{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#CV2 loads everythings as BGR\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "\n",
    "test_image_list = glob.glob(\"./test_images/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOG Feature Extractor\n",
    "def patch_analyzer(image, fd1=None, patch_loc=None, size=(16,16), nbins=16, bins_range=(0,256)):\n",
    "    if fd1 is None and patch_loc is None:\n",
    "        grey_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        fd, hog_image = hog(grey_img, orientations=8, pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(1, 1), visualise=True)\n",
    "    else:\n",
    "        y = patch_loc.startPosY\n",
    "        ypos_end = patch_loc.endPosY\n",
    "        x = patch_loc.startPosX\n",
    "        xpos_end = patch_loc.endPosX\n",
    "        #print(y,ypos_end, x, xpos_end)\n",
    "        hog_image = fd1\n",
    "        fd = fd1[y:ypos_end, x:xpos_end].ravel()\n",
    "\n",
    "\n",
    "    #Color Space Extraction\n",
    "\n",
    "    #conv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    conv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    #Downsample 0.25x from original\n",
    "    #Original patch is 64px\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    scale_feature = cv2.resize(conv_img, size).ravel() \n",
    "\n",
    "\n",
    "    #Create Histograms from scaled image\n",
    "    c1_hist = np.histogram(image[:,:,0], bins=nbins, range=bins_range)\n",
    "    c2_hist = np.histogram(image[:,:,1], bins=nbins, range=bins_range)\n",
    "    c3_hist = np.histogram(image[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((c1_hist[0], c2_hist[0], c3_hist[0]))\n",
    "\n",
    "\n",
    "    #Combine and Normalized Data\n",
    "    feature_list = [fd, scale_feature, hist_features]\n",
    "    # Create an array stack, NOTE: StandardScaler() expects np.float64\n",
    "    tmp_x = np.concatenate(feature_list).astype(np.float64)\n",
    "\n",
    "    return tmp_x, image, hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the classifier using patch_analyzer\n",
    "vehicles = glob.glob('vehicles/*/*.png')\n",
    "non_vehicles = glob.glob('non-vehicles/*/*.png')\n",
    "image_loc_list = non_vehicles + vehicles\n",
    "\n",
    "features_array = np.asarray([patch_analyzer(cv2.imread(image))[0] for image in tqdm(image_loc_list)])\n",
    "\n",
    "np.save('LinearSVC_GTI_KTTT', features_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "LinearSVC Reached\n",
      "[LibLinear]\n",
      "99.4196119196\n",
      "98.536036036\n"
     ]
    }
   ],
   "source": [
    "#Number of non-cars are represented by zeros\n",
    "#Number of cars are represented by ones\n",
    "img_labels = np.concatenate([np.zeros(8968), np.ones(8792)])\n",
    "\n",
    "features_array = np.load('LinearSVC_GTI_KTTT.npy')\n",
    "\n",
    "print(np.ndim(features_array))\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(features_array, img_labels, test_size=0.35)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print(\"LinearSVC Reached\")\n",
    "\n",
    "#Implement Linear SVM Classifier\n",
    "clf = LinearSVC(C=0.001,verbose=1, random_state=0)\n",
    "clf.fit(scaled_X_train, y_train)\n",
    "\n",
    "#Run trained classifier on test image\n",
    "print()\n",
    "\n",
    "print(clf.score(scaled_X_train, y_train)*100)\n",
    "\n",
    "print(clf.score(scaled_X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Reached\n",
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.load('LinearSVC_GTI_KTTT.npy')\n",
    "y_train = np.concatenate([np.zeros(8968), np.ones(8792)])\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "\n",
    "print(\"LinearSVC Reached\")\n",
    "\n",
    "#Implement Linear SVM Classifier\n",
    "clf = LinearSVC(C=0.001,verbose=1, random_state=0)\n",
    "clf.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnee/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,1328)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-e41da9ffa195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m                         cells_per_block=(1, 1), visualise=True)   \n\u001b[1;32m     62\u001b[0m     \u001b[0msearch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHLS_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_start_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_stop_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mpotential_cars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpotential_cars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHLS_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-e41da9ffa195>\u001b[0m in \u001b[0;36msearch_windows\u001b[0;34m(img_list)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhog_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mpositives_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartPosX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartPosY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendPosX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendPosY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,1328)"
     ]
    }
   ],
   "source": [
    "## Return a list of image patches\n",
    "test_image = cv2.imread(test_image_list[0])\n",
    "\n",
    "PatchImage = collections.namedtuple('PatchImage', ['image', 'startPosX', 'startPosY', 'endPosX', 'endPosY'])\n",
    "\n",
    "def sliding_window(img, y_start_scale=0, y_stop_scale=100, patch_size=64, stride=16, scale=1):\n",
    "    #Convert to float-32 value and normalize\n",
    "    image = img.astype(np.float32)/255\n",
    "    trans_img = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    imshape = trans_img.shape\n",
    "    y_start = np.int(imshape[0]/scale*(y_start_scale/100))\n",
    "    y_stop = np.int(imshape[0]/scale*(y_stop_scale/100))\n",
    "    x_stop = np.int(imshape[1]/scale)\n",
    "    if scale != 1:\n",
    "        trans_img = cv2.resize(trans_img, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        y_stop = np.int(imshape[0]/scale)\n",
    "\n",
    "    \n",
    "    patch_list = []\n",
    "    \n",
    "    for x in range(0, x_stop-patch_size, stride):\n",
    "        for y in range(y_start, y_stop-patch_size, stride):\n",
    "            ypos_end = y+patch_size\n",
    "            xpos_end = x+patch_size\n",
    "            cur_patch = trans_img[y:ypos_end, x:xpos_end]\n",
    "            #print((x, y), (xpos_end, ypos_end))\n",
    "            # Extract image and locations for this patch\n",
    "            patch_list.append(PatchImage(image=cur_patch, startPosX=x, startPosY=y, endPosX=xpos_end, endPosY=ypos_end))\n",
    "            #patch_list.append([cur_patch, (x, y), (xpos_end, ypos_end)])\n",
    "    return patch_list, trans_img\n",
    "\n",
    "#Feed function trained LinearSVC classifier and list of patches to predict locations\n",
    "def search_windows(img_list):\n",
    "    positives_list = []\n",
    "    for patch in img_list:\n",
    "        features = patch_analyzer(image=patch.image, fd1=hog_image, patch_loc=patch)[0]\n",
    "        prediction = clf.predict(X_scaler.transform(np.asarray(features)))\n",
    "        if prediction == 1:\n",
    "            positives_list.append([(patch.startPosX, patch.startPosY), (patch.endPosX, patch.endPosY)])\n",
    "    return positives_list\n",
    "\n",
    "# Here is your draw_boxes function from the previous exercise\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        # Coordinates expected in (x,y) and (x1,y1)\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "        #print(bbox[1][0])\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "#Iterate through three different scales\n",
    "scale_list = [0.5, 1, 1.5, 2]\n",
    "\n",
    "for scale in scale_list:\n",
    "    grey_img = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "    hfeat, hog_image = hog(grey_img, orientations=8, pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(1, 1), visualise=True)   \n",
    "    search_list, HLS_image = sliding_window(test_image, y_start_scale=50, y_stop_scale=95, scale=scale)\n",
    "    potential_cars = search_windows(search_list)\n",
    "    plt.imshow(draw_boxes(potential_cars, HLS_image))\n",
    "    print(scale)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlay outputs into heatmap, generate heatmap image + bounding box cluster images\n",
    "\n",
    "def heat_map(img, box_list, threshold=0):\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    #Iterate through all the positively identified windows\n",
    "    for entry in box_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        img[entry[0][1]:entry[1][1], entry[0][0]:box[1][0]] += 1\n",
    "    #Zero out pixels below the threshold\n",
    "    img[img <= threshold] = 0\n",
    "    return img\n",
    "\n",
    "#Labeled box code same as lesson function\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "#Draw bounding boxes around potential cars\n",
    "draw_image = np.copy(test_image)\n",
    "\n",
    "#Generate a list of boxes around positively identified cars\n",
    "box_list = search_windows(patch_list)  \n",
    "\n",
    "# Add heat to each box in box list and threshold the image for false positives\n",
    "heat = heat_map(draw_image,box_list, 2)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "labels = label(heatmap)\n",
    "bounded_image = draw_labeled_bboxes(draw_image, labels)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(bounded_image)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the input video and break it out into constituent frames\n",
    "print(cv2.__version__)\n",
    "vidcap = cv2.VideoCapture('')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "  success,image = vidcap.read()\n",
    "  print 'Read a new frame: ', success\n",
    "  box_list = search_windows(image)\n",
    "  # Add heat to each box in box list and threshold the image for false positives\n",
    "  heatmap = np.clip(heat_map(heat,box_list, 2), 0, 255)\n",
    "  #Merge the pixels\n",
    "  merged_cars = label(heatmap)\n",
    "  draw_labeled_bboxes(merged_cars)\n",
    "  cv2.imwrite(\"frame%d.png\" % count, image)     # save frame as PNG file\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all images with bounded boxes and compile into video\n",
    "img1 = cv2.imread('1.jpg')\n",
    "img2 = cv2.imread('2.jpg')\n",
    "img3 = cv2.imread('3.jpg')\n",
    "\n",
    "height , width , layers =  img1.shape\n",
    "\n",
    "video = cv2.VideoWriter('video.avi',-1,1,(width,height))\n",
    "\n",
    "video.write(img1)\n",
    "video.write(img2)\n",
    "video.write(img3)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
