{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#CV2 loads everythings as BGR\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_image_list = glob.glob(\"./test_images/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOG Feature Extractor\n",
    "def patch_analyzer(image, size=(16,16), nbins=16, bins_range=(0,256)):\n",
    "    grey_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fd, hog_image = hog(grey_img, orientations=8, pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(1, 1), visualise=True)\n",
    "\n",
    "    #Color Space Extraction\n",
    "\n",
    "    #conv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    conv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    #Downsample 0.25x from original\n",
    "    #Original patch is 64px\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    scale_feature = cv2.resize(conv_img, size).ravel() \n",
    "\n",
    "\n",
    "    #Create Histograms from scaled image\n",
    "    c1_hist = np.histogram(image[:,:,0], bins=nbins, range=bins_range)\n",
    "    c2_hist = np.histogram(image[:,:,1], bins=nbins, range=bins_range)\n",
    "    c3_hist = np.histogram(image[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((c1_hist[0], c2_hist[0], c3_hist[0]))\n",
    "\n",
    "\n",
    "    #Combine and Normalized Data\n",
    "    feature_list = [fd, scale_feature, hist_features]\n",
    "    # Create an array stack, NOTE: StandardScaler() expects np.float64\n",
    "    tmp_x = np.concatenate(feature_list).astype(np.float64)\n",
    "\n",
    "    return tmp_x, image, hog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the classifier using patch_analyzer\n",
    "vehicles = glob.glob('vehicles/*/*.png')\n",
    "non_vehicles = glob.glob('non-vehicles/*/*.png')\n",
    "image_loc_list = non_vehicles + vehicles\n",
    "\n",
    "features_array = np.asarray([patch_analyzer(cv2.imread(image))[0] for image in tqdm(image_loc_list)])\n",
    "\n",
    "np.save('LinearSVC_GTI_KTTT', features_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Reached\n",
      "[LibLinear]\n",
      "99.5235620236\n",
      "98.2786357786\n"
     ]
    }
   ],
   "source": [
    "#Number of non-cars are represented by zeros\n",
    "#Number of cars are represented by ones\n",
    "img_labels = np.concatenate([np.zeros(8968), np.ones(8792)])\n",
    "\n",
    "features_array = np.load('LinearSVC_GTI_KTTT.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(features_array, img_labels, test_size=0.35)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print(\"LinearSVC Reached\")\n",
    "\n",
    "#Implement Linear SVM Classifier\n",
    "clf = LinearSVC(C=0.001,verbose=1, random_state=0)\n",
    "clf.fit(scaled_X_train, y_train)\n",
    "\n",
    "#Run trained classifier on test image\n",
    "print()\n",
    "\n",
    "print(clf.score(scaled_X_train, y_train)*100)\n",
    "\n",
    "print(clf.score(scaled_X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Reached\n",
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.load('LinearSVC_GTI_KTTT.npy')\n",
    "y_train = np.concatenate([np.zeros(8968), np.ones(8792)])\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "\n",
    "print(\"LinearSVC Reached\")\n",
    "\n",
    "#Implement Linear SVM Classifier\n",
    "clf = LinearSVC(C=0.001,verbose=1, random_state=0)\n",
    "clf.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "#Return a list of image patches\n",
    "test_image = cv2.imread(test_image_list[0])\n",
    "\n",
    "def sliding_window(img, y_start=0, y_stop=1280, patch_size=64, pix_per_cell=8, cells_per_block=2, cells_per_step=1, orient=8, scale=1):\n",
    "    draw_img = np.copy(img)\n",
    "    #Convert to float-32 value and normalize\n",
    "    image = img.astype(np.float32)/255\n",
    "    img_window = img[y_start:y_stop,:,:]\n",
    "    trans_img = cv2.cvtColor(img_window, cv2.COLOR_BGR2HLS)\n",
    "    #Uncertain why they convert to YCC here\n",
    "    #trans_img = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = trans_img.shape\n",
    "        trans_img = cv2.resize(trans_img, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = trans_img[:,:,0]\n",
    "    ch2 = trans_img[:,:,1]\n",
    "    ch3 = trans_img[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)//cells_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)//cells_per_block + 1 \n",
    "\n",
    "    nxsteps = nxblocks // cells_per_step\n",
    "    nysteps = nyblocks // cells_per_step\n",
    "\n",
    "    patch_list = []\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*pix_per_cell*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            ypos_end = ypos+patch_size\n",
    "            xpos_end = xpos+patch_size\n",
    "            cur_patch = trans_img[ypos:ypos_end, xpos:xpos_end]\n",
    "            # Extract HOG for this patch\n",
    "            patch_list.append([cur_patch, (xpos, ypos), (xpos_end, ypos_end)])\n",
    "    return patch_list\n",
    "\n",
    "#Iterate through three different scales\n",
    "scale_list = [0.5, 1, 1.5]\n",
    "\n",
    "for scale in scale_list:\n",
    "    sliding_window(test_image, y_stop = 500)\n",
    "    print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed function trained LinearSVC classifier and list of patches to predict locations\n",
    "def search_windows(img_list):\n",
    "\tpositives_list = []\n",
    "\tfor entry in img_list:\n",
    "        prediction = clf.predict(X_scaler.transform(patch_analyzer(entry[0])[0]))\n",
    "        if prediction == 1:\n",
    "            positives_list.append(entry[1:])\n",
    "    return positives_list\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "\n",
    "#Overlay outputs into heatmap, generate heatmap image + bounding box cluster images\n",
    "\n",
    "def heat_map(img, box_list, threshold=0):\n",
    "\theat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\t#Iterate through all the positively identified windows\n",
    "\tfor entry in box_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "\t\timg[entry[0][1]:entry[1][1], entry[0][0]:box[1][0]] += 1\n",
    "\t#Zero out pixels below the threshold\n",
    "\timg[img <= threshold] = 0\n",
    "\treturn img\n",
    "\n",
    "#Labeled box code same as lesson function\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "#Draw bounding boxes around potential cars\n",
    "draw_image = np.copy(test_image)\n",
    "\n",
    "#Generate a list of boxes around positively identified cars\n",
    "box_list = search_windows(draw_image)  \n",
    "\n",
    "# Add heat to each box in box list and threshold the image for false positives\n",
    "heat = heat_map(heat,box_list, 2)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "labels = label(heatmap)\n",
    "draw_img = draw_labeled_bboxes(draw_image, labels)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
